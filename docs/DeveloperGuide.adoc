= Piconso - Developer Guide
:site-section: DeveloperGuide
:toc:
:toc-title:
:toc-placement: preamble
:sectnums:
:imagesDir: images
:stylesDir: stylesheets
:xrefstyle: full
ifdef::env-github[]
:tip-caption: :bulb:
:note-caption: :information_source:
:warning-caption: :warning:
:experimental:
endif::[]
:repoURL: https://github.com/se-edu/addressbook-level4/tree/master

By: `Team SE-EDU`      Since: `Jun 2016`      Licence: `MIT`

== Setting up

=== Prerequisites

. *JDK `9`* or later
+
[WARNING]
JDK `10` on Windows will fail to run tests in <<UsingGradle#Running-Tests, headless mode>> due to a https://github.com/javafxports/openjdk-jfx/issues/66[JavaFX bug].
Windows developers are highly recommended to use JDK `9`.

. *IntelliJ* IDE
+
[NOTE]
IntelliJ by default has Gradle and JavaFx plugins installed. +
Do not disable them. If you have disabled them, go to `File` > `Settings` > `Plugins` to re-enable them.


=== Setting up the project in your computer

. Fork this repo, and clone the fork to your computer
. Open IntelliJ (if you are not in the welcome screen, click `File` > `Close Project` to close the existing project dialog first)
. Set up the correct JDK version for Gradle
.. Click `Configure` > `Project Defaults` > `Project Structure`
.. Click `New...` and find the directory of the JDK
. Click `Import Project`
. Locate the `build.gradle` file and select it. Click `OK`
. Click `Open as Project`
. Click `OK` to accept the default settings
. Open a console and run the command `gradlew processResources` (Mac/Linux: `./gradlew processResources`). It should finish with the `BUILD SUCCESSFUL` message. +
This will generate all resources required by the application and tests. +
. Open MainWindow.java and other files to check for any code errors +
.. Due to an ongoing issue with some of the newer versions of IntelliJ, code errors may be detected even if the project can be built and run successfully +
.. To resolve this, place your cursor over any of the code section highlighted in red. Press ALT+ENTER, and select Add '--add-modules=…​' to module compiler options for each error +
. Repeat this for the test folder as well (e.g. check HelpWindowTest.java and other files for code errors, and if so, resolve it the same way)

=== Verifying the setup

. Run the `seedu.address.MainApp` and try a few commands
. <<Testing,Run the tests>> to ensure they all pass.

=== Configurations to do before writing code

==== Configuring the coding style

This project follows https://github.com/oss-generic/process/blob/master/docs/CodingStandards.adoc[oss-generic coding standards]. IntelliJ's default style is mostly compliant with ours but it uses a different import order from ours. To rectify,

. Go to `File` > `Settings...` (Windows/Linux), or `IntelliJ IDEA` > `Preferences...` (macOS)
. Select `Editor` > `Code Style` > `Java`
. Click on the `Imports` tab to set the order

* For `Class count to use import with '\*'` and `Names count to use static import with '*'`: Set to `999` to prevent IntelliJ from contracting the import statements
* For `Import Layout`: The order is `import static all other imports`, `import java.\*`, `import javax.*`, `import org.\*`, `import com.*`, `import all other imports`. Add a `<blank line>` between each `import`

Optionally, you can follow the <<UsingCheckstyle#, UsingCheckstyle.adoc>> document to configure Intellij to check style-compliance as you write code.

==== Setting up CI

Set up Travis to perform Continuous Integration (CI) for your fork. See <<UsingTravis#, UsingTravis.adoc>> to learn how to set it up.

After setting up Travis, you can optionally set up coverage reporting for your team fork (see <<UsingCoveralls#, UsingCoveralls.adoc>>).

[NOTE]
Coverage reporting could be useful for a team repository that hosts the final version but it is not that useful for your personal fork.

Optionally, you can set up AppVeyor as a second CI (see <<UsingAppVeyor#, UsingAppVeyor.adoc>>).

[NOTE]
Having both Travis and AppVeyor ensures your App works on both Unix-based platforms and Windows-based platforms (Travis is Unix-based and AppVeyor is Windows-based).

==== Getting started with coding

When you are ready to start coding,

1. Get some sense of the overall design by reading <<Design-Architecture>>.

== Design

[[Design-Architecture]]
=== Architecture

.Architecture Diagram
image::Architecture.png[width="600"]


The *_Architecture Diagram_* given above explains the high-level design of the App. Given below is a quick overview of each component.

[TIP]
The `.pptx` files used to create diagrams in this document can be found in the link:{repoURL}/docs/diagrams/[diagrams] folder. To update a diagram, modify the diagram in the pptx file, select the objects of the diagram, and choose `Save as picture`.

`Main` has only one class called link:{repoURL}/src/main/java/seedu/address/MainApp.java[`MainApp`]. It is responsible for,

* At app launch: Initializes the components in the correct sequence, and connects them up with each other.
* At shut down: Shuts down the components and invokes cleanup method where necessary.

<<Design-Commons,*`Commons`*>> represents a collection of classes used by multiple other components. Two of those classes play important roles at the architecture level.

* `EventsCenter` : This class (written using https://github.com/google/guava/wiki/EventBusExplained[Google's Event Bus library]) is used by components to communicate with other components using events (i.e. a form of _Event Driven_ design)
* `LogsCenter` : Used by many classes to write log messages to the App's log file.

The rest of the App consists of four components.

* <<Design-Ui,*`UI`*>>: The UI of the App.
* <<Design-Logic,*`Logic`*>>: The command executor.
* <<Design-Model,*`Model`*>>: Holds the data of the App in-memory.
* <<Design-Storage,*`Storage`*>>: Reads data from, and writes data to, the hard disk.

Each of the four components

* Defines its _API_ in an `interface` with the same name as the Component.
* Exposes its functionality using a `{Component Name}Manager` class.

For example, the `Logic` component (see the class diagram given below) defines it’s API in the `Logic.java` interface and exposes its functionality using the `LogicManager.java` class.

.Class Diagram of the Logic Component
image::LogicClassDiagram1.png[width="800"]

[discrete]
==== Events-Driven nature of the design


[[Design-Ui]]
=== UI component
image::UiClassDiagram_Piconso.png[width="800"]

*API* : link:{repoURL}/src/main/java/seedu/address/ui/Ui.java[`Ui.java`]

The UI consists of a `MainWindow` that is made up of parts e.g.`CommandBox`, `ResultDisplay`,
`HistoryListPanel`, `FilmReel`, `ImagePanel` etc. All these, including the `MainWindow`,
inherit from the abstract `UiPart` class.

The `UI` component uses JavaFx UI framework. The layout of these UI parts are defined in matching `.fxml` files that
are in the `src/main/resources/view` folder. For example, the layout of the link:{repoURL}/src/main/java/seedu/address/ui/MainWindow.java[`MainWindow`] is specified in link:{repoURL}/src/main/resources/view/MainWindow.fxml[`MainWindow.fxml`]

The `UI` component,

* Executes user commands using the `Logic` component.
* Binds itself to some images in the `Model` so that the UI can auto-update when data in the `Model` change.
* Responds to events raised from various parts of the App and updates the UI accordingly.

_{To be updated}_

[[Design-Logic]]
=== Logic component
image::LogicClassDiagram1.png[width="800"]

*API* :
link:{repoURL}/src/main/java/seedu/address/logic/Logic.java[`Logic.java`]

.  `Logic` uses the `PiconsoParser` class to parse the user command.
.  This results in a `Command` object which is executed by the `LogicManager`.
.  The command execution can affect the `Model` (e.g. converting an image) and/or raise events.
.  The result of the command execution is encapsulated as a `CommandResult` object which is passed back to the `Ui`.

_{To be updated}_

[[Design-Model]]
=== Model component
image::ModelClassDiagram_Piconso.png[width="800"]

*API* : link:{repoURL}/src/main/java/seedu/address/model/Model.java[`Model.java`]

The `Model`,

* stores a `UserPref` object that represents the user's preferences.
* stores the `Canvas` for the current image.
* does not depend on any of the other three components.

_{To be updated}_

[[Design-Storage]]
=== Storage component
_{To be updated}_

[[Design-Commons]]
=== Commons component
_{To be updated}_

== Implementation
_{In Progress}_ +
This section describes some noteworthy details on how certain features are implemented.

// tag::cd[]
=== Change Directory (Cd) feature
The Cd feature is implemented to allow users to access images in the different directories within their home system.
This removes the restrictions of accessing only images from one particular folder.

==== Current Implementation
The Cd mechanism is facilitated by the `ModelManager`. It contains the operations `Model#getCurrDirectory` and
`Model#updateCurrDirectory(Path)` respectively.

The Model calls upon `UserPrefs` within the respective operations. The `UserPrefs` class contains the current directory
the user's in, stored internally as `currDirectory` and implements the following operations:

* `UserPrefs#getCurrDirectory()` - Returns the user's current directory.
* `UserPrefs#updateUserPrefs(Path)` - Updates the user's current directory with the updated Path.

Within the operation `UserPrefs#updateUserPrefs(Path)`, it also retrieves the list of images within the directory,
which are stored internally as `imageList`. This would facilitates the `Select` feature in our application
(refer to 3.2).

Additionally, to ease user's experience, similar to the actual usage of the cd command, this feature also uses the `tab`
function to auto-complete the directory name if it exists.

[NOTE]
Pressing tab again will display the next directory with the given prefix.

Given below is an example usage scenario and how the cd mechanism behaves at each step.

Step 1. The user launches the application for the first time. The `UserPrefs` will be initialized with the `currDirectory`
as the user's home directory.

Step 2. The user executes `cd Desktop` command to navigate into the Desktop directory. The cd command calls
`Model#getCurrDirectory()` and appends `Desktop` to the end of the current directory. It then checks if the new Path is
a directory and calls `Model#updateCurrDirectory(Path)` and update the new Path in `UserPrefs` if the check returns true.

The following sequence diagram shows how the cd command works:

image::CdSequenceDiagram.png[width=800]

[NOTE]
If the `newCurrDirectory` is not a directory, i.e. `isDirectory()` returns false, then there is no change in
`currDirectory` state in `UserPrefs`. If so, it will return a failure message to the user rather than attempting to update
`currDirectory`.

==== Design Considerations
===== Aspect: How cd executes

* *Alternative 1 (current choice)*: Retrieves and updates current directory in `UserPrefs`.
** Pros: Easy to implement and every command can access the current directory.
** Cons: Appends and checks if path exists after every cd command entered.

* *Alternative 2* : Stores path that exists in a HashSet.
** Pros: Do not need to append and check, and just check if it exists in HashSet.
** Cons: Does not update existing path if user deletes a directory.
// end::cd[]

// tag::open[]
=== Open feature
The Open Command allow users to open the images in a batch of 10 images within the directory for image-editing.
This command is further facilitated by the Next/Prev Command.

==== Current Implementation
The implementation of the Open feature is largely similar to the `Cd Command`. It is facilitated by the `ModelManager`
and contains the following operations:

 * `Model#getDirectoryImageList()` -- Retrieves the stored list of images in UserPrefs.
 * `Model#updateCurrentOriginalImage(Image, Path)` -- Updates the model with the current selected images.

The `Model` calls upon `UserPrefs` to retrieve the `imageList` of the current
batch. The `UserPrefs` class implements the following operation:

* `UserPrefs#getCurrImageListBatch()` -- Returns the current batch of images.

The `Model#updateCurrentOriginalImage(Image, Path)` operation stores the path of the selected image and the
`PreviewImage` instance of it as `currOriginalImage` and `currentPreviewImage` respectively within the `ModelManager`.
Additionally, the operation also creates a canvas and a layer to facilitate the `transmission` feature.

Given below is an example usage scenario and how the open mechanism behaves at each step.

Step 1. The user launches the application for the first time. The `UserPrefs` will be initialized with the `currDirectory`
as the user's home directory.

Step 2. The user executes `cd Desktop` command to navigate into the Desktop directory. The cd command will initialise
the `imageList` with all the images within Desktop.

image::SelectCommand1.png[width=800]

Step 3. The user executes `open 1` command to open the first image in the first batch of 10 images. The open
command calls `Model#getDirectoryImageList()` to retrieve the first batch of images within Desktop. The first image is
then retrieved and displayed on the GUI.

image::OpenCommand2.png[width=500]

Step 4. The user then executes `open 5` command to select the fifth image in the batch of 10 images. The fifth image
is then retrieved similarly and displayed on the GUI.

image::OpenCommand3.png[width=450]

The following sequence diagram shows how the open command works:

image::OpenSequenceDiagram.png[width=800]

==== Design Considerations
===== Aspect: How select executes

* *Alternative 1 (current choice)*: Open images within the BATCH_SIZE.
** Pros: Users work on a small size of images.
** Cons: Limited to the batch size.

* *Alternative 2* : Select images within the `imageList` size.
** Pros: Easy to retrieve images anywhere in the list.
** Cons: Can be very messy if the `imageList` size is too large.
// end::open[]

// tag::nextprev[]
=== Next/Prev feature

The Next Command retrieves the next 10 images in the image list.

On the contrary, the Previous Command retrieves the previous 10 images in the image list.

==== Current Implementation
The implementation of the Next/Previous feature is also similar to the `Cd Command`. It is facilitated by the `ModelManager`
and contains the operations: `Model#updateImageListNextBatch()` and `Model#updateImageListPrevBatch()`.

The `Model` calls upon `UserPrefs` which stores and facilitates the retrieval of the current
batch of images using the `currBatchPointer`. The `UserPrefs` class implements the following operation:

* `UserPrefs#updateImageListNextBatch()` -- Adds the `currBatchPointer` by 10.
* `UserPrefs#updateImageListPrevBatch()` -- Minus the `currBatchPointer` by 10.

Given below is an example usage scenario and how the next/previous mechanism behaves at each step.

Step 1. The user launches the application for the first time. The `UserPrefs` will be initialized with the `currDirectory`
as the user's home directory.

Step 2. The user executes `cd Desktop` command to navigate into the Desktop directory. The cd command will initialise
the `imageList` with all the images within Desktop.

image::SelectCommand1.png[width=800]

Step 3. The user executes `next` command to retrieve the next 10 images within Desktop.

image::NextPrevCommand2.png[width=800]

Step 4. The user executes `prev` command to retrieve the previous 10 images within Desktop.

image::NextPrevCommand3.png[width=800]

The following sequence diagram shows how the next command works:

image::NextSequenceDiagram.png[width=800]

The following sequence diagram shows how the prev command works:

image::PrevSequenceDiagram.png[width=800]

===== Aspect: How next/previous executes

* *Alternative 1 (current choice)*: Keeps track of current batch with a pointer.
** Pros: Easy to access current batch images.
** Cons: Efficiency might be lower for directories with many images.

* *Alternative 2* : Separate images in batches and store in array.
** Pros: Fast to access next/previous batches.
** Cons: Harder to handle changes in a batch (e.g. image got deleted) within the array.
// end::nextprev[]

// tag::undoredo[]
=== Undo/Redo feature
==== Current Implementation

The undo/redo works on the `currentLayer` the user is working on. Each `Layer` contains a `PreviewImage` which facilitates the undo/redo mechanism.
The mechanism works by caching the original image and transformed images in a temporary `cache` folder, and using `currentStatePointer` as a pointer together with `currentSize` as an indicator to manage the caching.
Undoing and redoing will shift the `currentStatePointer` accordingly while each transformation commits the image by writing to the `cache` folder (purging redundant images if needed).

[NOTE]
To work with multiple layers, each `Layer` has a single `PreviewImage` which is initialized with a unique `LayerId`, so that the `PreviewImage` can cache its images safely without conflicting image names.

Additionally, it implements the following operations:

* `PreviewImage#commit()` -- Writes the newly transformed `BufferedImage` into the `cache` folder (purge redundant images if needed).
* `PreviewImage#getImage()` -- Returns the current `BufferedImage` state of the `previewImage` by reading from the `cache` folder.
* `PreviewImage#undo()` -- Shifts the `currentStatePointer` to the left, pointing to the previous state.
* `PreviewImage#redo()` -- Shifts the `currentStatePointer` to the right, pointing to a previously undone state.

These operations are exposed in the `Model` interface as `Model#updateCurrentPreviewImage()`, `Model#undoPreviewImage()` and `Model#redoPreviewImage()`.

Given below is an example usage scenario and how the undo/redo mechanism behaves at each step.

Step 1. The user selects an image with the `select` command. The `Canvas` is initialized with a new `Layer` which initializes its own `PreviewImage` with the selected image. The `currentStatePointer` pointing to that state.

[NOTE]
A `Canvas` can already be initialized, meaning this is an additional layer being added. The `Layer` and `PreviewImage` gets initialized the same way.


image::undoRedo1.png[width="800"]

Step 2. The user executes a series of transformations. Each time, the newly transformed `BufferedImage` is stored by writing it to the `cache` folder. The `currentStatePointer` is also incremented. Eg. `hue`, `mirror`, `blur`

[NOTE]
If a command fails its execution, it will not call `Model#updateCurrentPreviewImage()`, so nothing will be cached.

image::undoRedo2.png[width="800"]

Step 3. The user wants to undo the previous action by using the `undo` command. It will call `Model#undoPreviewImage()` which will shift the `currentStatePointer` once to the left, pointing it to the previous `PreviewImage` state. After which, that previously cached `BufferedImage` will be read and rendered to update the UI's preview image pane.

[NOTE]
If the `currentStatePointer` is at index 0, pointing to the initial state, then there are no previous states to restore. The `undo` command uses `Model#canUndoPreviewImage()` to check if this is the case. If so, it will return an error to the user rather than attempting to perform the undo.

image::undoRedo3.png[width="800"]


Step 4. The user executes another transformation, which calls `Model#updateCurrentPreviewImage`. Since the `currentStatePointer` is not pointing at the end state (`currentSize - 1`), and the states after the `currentStatePointer` will not make sense, all states after the pointer will be purged.

image::undoRedo4.png[width="800"]

//Step 5. The user decides to undo several actions. The user uses the `undo` command followed by the number of actions to undo eg.`2`. The `currentStatePointer` derements accordingly. The model's `previewImage` is to the pointed state.
//
//image::undoRedo5.png[width="800"]

The following sequence diagram shows how the undo operation works:

image::undoRedoSequenceDiagram.png[width="800"]

The redo command does the opposite — it calls `Model#redoPreviewImage()`, which shifts the currentStatePointer once to the right, pointing to the previously undone state.

[NOTE]
If the `currentStatePointer` is at index `currentSize - 1`, pointing to the `PreviewImage's` last state, then there are no undone states to restore. The `redo` command uses `Model#canReddoPreviewImage()` to check if this is the case. If so, it will return an error to the user rather than attempting to perform the redo.


The following activity diagram summarizes what happens when a user executes a new transformation:

image::undoRedoActivityDiagram.png[width="800"]

The following activity diagram summarizes what happens when a user executes the undo command:

image::undoRedoActivityDiagram2.png[width="800"]

The following activity diagram summarizes what happens when a user executes the redo command:

image::undoRedoActivityDiagram3.png[width="800"]

==== Undo-all and Redo-all
The commands `undo-all` and `redo-all` follow the same implementation as undo and redo. They provide a convenient way to quickly undo and redo all transformations to the current layer's `PreviewImage` for the user.

* `undo-all` shifts the `PreviewImage's` pointer to 0, pointing at the original state.

* `redo-all` shifts the `PreviewImage's` pointer to `currentSize - 1`, the state with all the applied transformations.

==== HistoryListPanel

The HistoryListPanel provides a view for the user to see the history of transformations applied.
Whenever a transformation is done or when a undo/redo command is executed, the `Model#refreshHistoryList()` is executed which refreshes the `HistoryListPanel` with a `HistoryUpdateEvent` containing the current layer's `PreviewImage's` list of transformations.
A view of the panel is shown below:

image::historyPanel.png[width="200"]


==== Design Considerations

===== Aspect: How undo & redo executes

* **Alternative 1 (current choice):** Saves each newly transformed image (including original).
** Pros: Easy to implement.
** Cons: Uses user's storage space for caching.
* **Alternative 2:** Save only the command, and reverse/reapply transformation for each undo/redo.
** Pros: Will not need to use user's data storage.
** Cons: Transformations on images take significantly more time as compared to reading and writing cache. Also, reversing of transformations are not possible for commands like `blur` and `colorspace`.
// end::undoredo[]


=== Transmission feature
==== Current Implementation

The transmission mechanism is facilitated by ImageMagick execute file.
It is an execute file which can be use to do the processing to the target image with specified commands given.
There is a ImageMaigcUtil class which will check, create, and run the imagemagick executable file,
a convertCommand to apply the specified transformation to the image,
a createConvertCommand to customise the transformation and store the command.
Additionally, there is a demo given in the example command, which is able to do the blur, resize, contrast... on the target image just for demo testing.
There are some main operations and processes in the class above.

==== ImageMagicUtil:

This class is used to provide the methods touching the ImageMagic package

* `getImageMagickZipUrl()` -- get the Url of the ImageMagick zipped package inside the resource.
* `getPlatform()` -- get the platform of the current OS.
* `getExecuteImageMagick()` -- get the path to the execute file of the ImageMagic.
* `parseArguments()` -- parse the argument from the operation.
* `processImage()` -- process the specified transformation to the image.
* `runProcessBuilder()` -- run the process builder with the arguments given
* `copyOutside()` -- copy the ImageMagick outside and unzip
// tag::convert[]
==== ConvertCommand:

this command is exposed to the model as `Model#addTransformation()`, which is used to update the transformatioSet of the currentPreviewImage.

Given below is an example usage scenario and how the transmission should behave at each step.

Step 1. The first time run the app, the corresponding zipped package of the ImageMagick will be copied outside, and unzipped,
a temp folder will also be created.

Step 2. The user selects an image with the `select` command. the method `model.getPreviewImage()` will be called to get he bufferedImage of the current preview scene.

Step 3. The user enter the command which need processing to the image selected with arguments, for instance "blur 0x8" "resize 50%",
the entered command will be parsed and the corresponding transformation will be created.

[NOTE]
If the input is invalid for the command enter, the processing of the image will not be done, and a reminder will be given to the user.


Step 4. the transformation will be added to the transformation set store in the preview image in the model.

[NOTE]
if the transformation Set got from the model is invalid, an error should be prompted

Step 5. An process builder will be built inside the method `processImage` which will take the image stored,
the processing info stored in the transmission set, use the ImageMagic executable file to do the processing,
then store the modified image in the temp folder created.


Step 6. The output bufferedImage will be generated by the modified file stored in the temp folder, and the stored file will be removed.

image::ConvertCommand.png[width="800"]

// end::convert[]
// tag::create[]
==== CreateConvertCommand:

This command is to create a customised command and store in the disk, will check the transformations specified by `checkValidation()` first.

Given below is an example usage scenario and how the transmission should behave at each step.

Step 1. The user enters the name of the customized, the transformations specified sequentially.

Step 2. The specified transformations will be parsed and checked by the templates store in the app.
[NOTE]
if the specified transformations has invalid name or arguments, error will be thrown and user will be reminded.

Step 3. The validated new command will be stored in the json for in the PiconsoCommands folder create when first time run the app.
==== Design Considerations

 - As the ImageMagic executable file is only able to handle the command line input and need the path of the image, we have to store the file in some tmp folder adn then, remove the modified image.

 - As in the processing process, it could be slow, and it is for one image only, then, in the mass images processing, multiple threads might be needed.
// end::create[]
// tag::save[]
=== Save feature
==== Current Implementation
The save command is to save the current preview image to the disk where the current image is selected,
use enter the name of the image and the format of the name will be validated.

* `isFormatValid()` is to validate the format of the filename user enters

Given is an example of how to use the command

Step 1. parse the image name user enters, get the name and the format of the filename.

Step 2. check whether the file exists or not, throw error is existing

Step 3. check the format of the image, if the format is not supported, error will be thrown

image::SaveCommand.png[width="800"]
// end::save[]
// tag::google[]
=== Google Features
==== Overall Introduction
The Google commands allow for access to https://developers.google.com/photos/library/guides/get-started-java[Google Photos] through a logged-in instance of the user, and are held up by two main components.

* `PhotosLibraryClientFactory` - Initiates and carries out the login process. Produces a `PhotoHandler` instance, which handles matters related to Google commands.
* `PhotoHandler` - Mainly consists of a `PhotoLibraryClient` instance and user's logged in state. Performs all explicit calls to Google Photos through the `PhotosLibraryClient` instance.
** The `PhotoHandler` instance is later accessed through `Model#getPhotoHandler()` and `Model#setPhotoHandler()``.

There are 5 main google-related commands, with the first two commands to login/logout a user, and the latter 3 being overloaded command types with `GoogleCommand` as the abstract parent class.

* `LoginCommand` - Logs in user to their Google Account.
* `LogoutCommand` - Logs a user out of their Google Account.
* `GoogleLsCommand` - Returns the files from Google Photos.
* `GoogleDlCommand` - Downloads the specified image(s) from Google Photos to the user's currently viewed local directory.
* `GoogleUploadCommand` - Uploads the specified image(s) from the user's currently viewed local directory to Google Photos.

To use Google Photos API in Piconso, we have connected and generated `client_credentials.json` via our own Google Account to enable usage of the API. It is suggested that you https://developers.google.com/photos/library/guides/get-started-java[configure] Piconso to use Google Photos Library API with your own account rather than the provided. +
If you are not familiar with how Google Photos work, it would be advisable to first try out Google Photos as a consumer before proceeding.

=== Login(login) Command

==== Current Implementation
The Login command currently authenticates a user via Google OAuth. To learn more about the implementation of OAuth methods, you may refer to https://developers.google.com/identity/protocols/OAuth2#installed[O-Auth Explanation] and https://developers.google.com/api-client-library/java/google-api-java-client/oauth2#installed_applications[Google API examples]. As the workings of Google OAuth are rather complicated, it is suggested that you go through the examples/documentations in those links. +

Below are some examples on how the login command will work.

[NOTE]
If connection to the internet is lost at any point during authentication with Google's server, login will fail and an error message will be sent to user as feedback.

==== Scenario 1: Explicit `login` command executed, user not logged in yet.

Step 1. The user executes a `login` command.

Step 2. The login command calls `Model#getPhotoHandler()` and checks if a PhotoHandler instance already exists, if false, it calls `PhotoLibraryClientFactory#createClient()` to set up the requirements for log in and redirects the user to the browser.

Step 3. The returned refresh token is stored, and PhotoLibraryClientFactory instance then calls `PhotoLibraryClientFactory#createPhotosLibraryClient()` and `PhotoLibraryClientFactory#getUserEmail() to instantiate a `PhotoHandler` instance

Step 4. The `PhotoHandler` instance is set by model as `Model#photoLibrary`, and confirmation of login is sent to user.

The following sequence diagram illustrates how the above steps work:

.Sequence Diagram for Login Command
image::LoginSequenceDiagram.png[width="2000"]

WARNING: Currently, the user MUST go through with the login process once activated else Piconso will freeze. Suggestions are to implement asynchronous login in v1.4 or by v2.0

==== Scenario 2: Implicit login, where Piconso auto logs in user upon re-launch

Step 1: Upon Piconso start up, `PhotoLibraryClientFactory#loginUserIfPossible()` is run by `ModelManager` +
Step 2: The method checks for stored credentials (refresh token), and logs in the user if it exists via `PhotoLibraryClientFactory#createClient()`, else the log in process is skipped.

In both scenarios, whenever a refresh token is found stored the user is logged in without having to face browser re-direct again. At no point in any scenario will we be storing a user's actual credentials. The only thing we will store is a refresh token that allows us to keep a user logged in, actual credentials are handled by Google OAuth +

==== Logout (logout) Command
The logout command works in a simple manner. It deletes the stored credential file if it exists, and does nothing if it does not. Upon deleting the file, the user will no longer have a refresh token to stay logged in, and thus is effectively logged out.

=== GoogleLsCommand (list)

[NOTE]
For all Google Commands (excluding login and logout), they will be called by commands appended with a g (i.e `g ls`, `g dl image.png`). +

Thus a `g` command will always be passed through a `GoogleCommandParser` before launching its respective command os launched.

==== Current Implementation
The GoogleLsCommand allows users to browse through their stored images on Google Photos. Currently, it is overloaded with three types of commands the user can type

`g ls` -> Lists all photos in user's Google Photos, takes a longer amount of time depending on the number of images stored. +
`g ls /a` -> Lists all albums in user's Google Photos. +
`g ls <ALBUM_NAME>` -> Lists all photos in specified album from Google Photos.

As such, parsing will be done twice. Once by GoogleCommandParser, and another within GoogleLsCommand itself.

==== Example: `g ls`, where user wants to list all albums in Google Photos.

Step 1. The user executes a `g ls /a` command.

Step 2. The command goes through parsing, firstly by `GoogleCommandParser` and secondly filtered by GoogleLsCommand. It is determined to be for listing albums, and `model.getPhotoHandler().returnAllAlbumsList()` is called.

Step 3. Within that method, it makes a request to Google Photos, retrieves a list of `Album`s, and stores them in a `Map<String, Album>` with each key being the album name.

Step 4. The entire list is converted into a String, and returned to the `CommandBox` ui as feedback to the user

The following sequence diagram illustrates how the above steps work:

.Sequence Diagram for GoogleLsCommand
{IMAGE TO BE ADDED}

The process is similar for the other 2 variants, except images or images from a specific album are retrieved instead. All retrieved results are always stored in their respective maps. i.e A Map for Albums, one for images, and another for images from a specific Album.

==== Design Considerations
* 1. Performance Issues
** The larger the amount of pictures stored in Google Photos, the longer amount of time a `g ls` command will take.
*** Current Solution: A fair warning of this issue is provided in the User Guide for users, and alternative command `g ls <ALBUM_NAME>` has been provided to encourage the user to input narrower searches
*** Improved Solution (to be implemented in earliest v1.4): The current implementation makes it so that the list of photos/albums is re-retrieved upon every `ls` call. As it is not likely that the set of photos in Google Photos will constantly change, a better alternative, a `refresh` command can be implemented alongside the other commands, such that the list is only re-retrieved when a user refreshes.

* 2. Duplicated Naming
** Google Photos allows for multiples images and albums to be stored with the same name, making it difficult to list item names as names might overlap.
*** Alternative 1 (Current): Before storing names of images/albums into the map, names are checked against the map for duplicates, and are appended with a suitable index if a file/album with the same name is found. This ensures that all files/albums are uniquely named.
**** Con: If there are multiple images with the same name, the process of any `g ls` will take a much longer time to run.

*** Alternative 2: Instead of storing the name of the image/album as the key inside the Map, the unique ID (that is retrieved together with the files from Google) can be used instead. This approach was however avoided for convenience of the user (ID too complicated to input)

* 3. Album Traversal
** Alternative 1: Treat the album as a category, thus `g ls <ALBUM_NAME>` acts as a filter that filters photos by category.
*** Con: The command to download from an album needs to be extended such that users need to specify in which album the image to download is in.

** Alternative 2: Handle the concept of albums like directories, such that a user can cd in and out of an album. This was avoided for fear of causing confusion in users (having to view both google and local directories concurrently).

=== GoogleDlCommand (download)

Step 1. The user executes a `g ls /a` command.

Step 2. The command goes through parsing, firstly by `GoogleCommandParser` and secondly filtered by GoogleLsCommand. It is determined to be for listing albums, and `model.getPhotoHandler().returnAllAlbumsList()` is called.

Step 3. Within that method, it makes a request to Google Photos, retrieves a list of `Album`s, and stores them in a `Map<String, Album>` with each key being the album name.

Step 4. The entire list is converted into a String, and returned to the `CommandBox` ui as feedback to the user

[NOTE]
For all upload/download related commands, the amount of time taken to process the task varies with the number of images to upload/download.

==== Current Implementation
The GoogleDlCommand allows users to browse through their stored images on Google Photos. Currently, it is overloaded with three types of commands the user can type

`g dl /i<IMAGE_NAME>`: Downloads specified image from Google Photos +
`g dl /a<ALBUM_NAME>`: Downloads all images from specified album in Google Photos, takes a longer amount of time depending on the number of images stored in the album. +
`g dl /a<ALBUM_NAME> /i<IMAGE_NAME>`: Downloads a specific photo from a specific album in Google Photos.

As such, parsing will be done twice. Once by GoogleCommandParser, and another within GoogleDlCommand itself.

{To be updated}

=== GoogleUploadCommand (upload)

{to be updated}
// end::google[]

// tag::canvas[]
== Canvas and Layer features

=== General overview
The `Canvas` and `Layer` classes serve as a layer of encapsulation for handling one or more instances of `PreviewImage`.
This is in line with good defensive coding practices and separation of concerns.

=== Canvas (canvas) command
Similar to the `google` set of commands, there are a set of overloaded command types inheriting from `CanvasCommand`
, namely:

* `bgcolor` - Sets the background colour of the canvas.
* `size` - Sets the height and the width of the canvas.
* `auto-resize` - Toggles the auto-resize property of the canvas.

==== Current implementation
Canvas manages various properties made accessible through the `ModelManager` class.
Layer order is preserved as it important for image composition.

Canvas implements the following accessors and utility functions:

* `getLayers` - returns an ordered list of layers which is guaranteed to be neither `null` or empty.
* `getLayerNames` - returns a list of layer names in order.
* `addLayer` - adds a given `PreviewImage` into the canvas on its own layer.
* `getCurrentLayer` - returns the current instance of the layer that is being operated on.
* `getCurrentLayerIndex` - returns the index of the current instance of the layer that is being operated on.
* `setCurrentLayer` - sets the layer to be operated on.
* `removeLayer` - removes a layer at a given index. The current layer and the last remaining layer in a canvas cannot be removed.

All of these functions are exposed through the `Model` interface.
Implementations in `ModelManager` usually include a call to the corresponding accessor along with utility functions to manage the state of the UI.

Beneath the hood `Canvas` manipulation is powered by ImageMagick.
All of the properties represented in `Canvas` are transformed into their respective flags or arguments in ImageMagick.
For example, the `isCanvasAuto` property is transformed into the flag `-flatten` if false and `-layers merge` if true.

The `processCanvas` is a factory method that handles this transformation, returning an instance of a `ProcessBuilder`.
The `ProcessBuilder` is then passed to `ImageMagickUtils#runProcessBuilder` which executes the process and stores the output in a BufferedImage.

.Sequence Diagram for Canvas Command
image::CanvasSequenceDiagram.png[width="2000"]

The above diagram illustrates the process of parsing and executing of `canvas` commands.

. The user executes any command beginning with `canvas`.

. The command is first parsed by `PiconsoParser` which picks up the `canvas` keyword and passes any remaining arguments to `CanvasCommandParser`.

. `CanvasCommandParser` determines the appropriate sub-command being executed and performs the requested operation on the canvas.

==== Design considerations

**Manipulation of the `ProcessBuilder`**

[.underline]#Alternatives#

Storing arguments directly in a `List<T>` where T is a custom type that implements `Comparable<T>` to ensure that arguments are in the correct order. A helper function will then map the `T` to a `String` and the resultant `List<String>` will be used to construct the necessary `ProcessBuilder`.

[.underline]#Evaluation#

While insertion of new layers and properties will be extremely easy, modifying or removal of existing properties will involve searching through the entire list. As a result, this method is extremely hard to grok and performs poorly upon update or deletion of existing properties.

=== Layer (layer) commands

The `layer` command follows a similar pattern as the `canvas` command.
The following sub-commands inherit from `LayerCommand`:

* `add` - Adds a layer from the `Canvas` and generates a layer name.
* `delete` - Removes a layer from the `Canvas`. The current layer and the last remaining layer cannot be removed.
* `select` - Selects a layer to work on.
* `swap` - Swaps the order of two distinct layers.

==== Current implementation

`Layer` implements a few key accessors and utility functions. Some of them include:

* `addTranformation` - Adds a given transformation into its `PreviewImage`++'s++ `TransformationSet`.
* `getName` - Gets the name of the layer.
* `setHeight` - Sets the height of the layer.
* `setWidth` - Sets the width of the layer.
* `setPosition` - Sets the x and y coordinates of the layer.

The following image illustrates the coordinate system adopted in Piconso.

image::coords.png[width="2000"]

The default anchor point is the top-left corner, this means that a `layer position -10x-10` command will set that layer's top left corner at `(-10, -10)`.
It is possible to have negative co-ordinates although clipping will occur unless the canvas is set to auto-resize.


.Sequence Diagram for Layer Command
image::LayerSequenceDiagram.png[width="2000"]

The above diagram illustrates the process of parsing and executing of `canvas` commands.

.  The user executes any command beginning with `layer`.

.  The command is first parsed by `PiconsoParser` which picks up the `layer` keyword and passes any remaining arguments to `LayerCommandParser`.

.  `LayerCommandParser` determines the appropriate sub-command being executed and performs the requested operation on the canvas and current layer.

==== Design Considerations

**Further manipulation of the `ProcessBuilder`**

[.underline]#Alternatives#

It is actually possible to nest `ImageMagick` commands which means that it is possible to keep separate `List<T>`++s++ and conjugate them when the canvas needs to be rendered.
The resultant ImageMagick command will take the form :

 magick [overall canvas flags] {[canvas flag] (individual layer flags)} [overall canvas flags]

Where blocks enclosed by `{ }` need to be repeated per layer.

[.underline]#Evaluation#

This solution is the most straight-forward and results in no intermediate files which is usually desirable. However, the resultant ImageMagick command will short circuit and cause the entire expression to fail if any of flags are incompatible or incorrect. Caching is also impossible, causing the whole canvas and all of its layers to be composed again from scratch.

This results in a poor user experience and hence we have decided against it.

=== Canvas and Layers in action

As the `canvas` and `layer` commands compliment each other, let's walk through a typical user's session in Piconso from start to finish.

. The user executes a valid `open` command:
A `Canvas` is constructed holding exactly one `Layer`
with the default height and width being that of the image selected.

. The user adds a new layer to the canvas:
`Canvas#addLayer` is executed and the helper functions in `ModelManager` refreshes the UI.

. The user swaps the order of the two layers to such that the original image is back on top:
`Canvas#swapLayer` makes the magic happen by swapping the two entries in the list of layers.

. While still on the original layer, the user moves it to the top left: `Layer#setPosition` moves the first layer out of the way.

. The user changes decides to work on the second layer and enters `layer select 2`:
`Canvas#setCurrentLayer` changes the current layer to the given index and internally keeps track of the index as well.

. A transformation is applied by the user to the current layer: `Canvas#addTransformation` appends the new Transformation to the current Layer's.
Note that no image processing occurs until a new render is requested. The `Canvas` class provides mutators and accessors.

. After a `canvas size 80x60`command: The new `Canvas#setSize` is applied upon the next render and it crops the image to a fraction of what it used to be.
Remember that resizing and scaling is accomplished with the `apply resize` command!

. Quickly realising his mistake, the user sets the canvas to fit his all of his layers: `Canvas#setCanvasAuto` toggles a boolean.

. The user finishes his piece by filling in the default transparent background with a `canvas bgcolor ++#++707070` : a hex color code is accepted by `Canvas#setBackgroundColor`.

.Results of various commands. The black bounding rectangle indicate the canvas size.
image::CanvasLayersDemo.png[width="2000"]


// end::canvas[]

== Documentation

We use asciidoc for writing documentation.

[NOTE]
We chose asciidoc over Markdown because asciidoc, although a bit more complex than Markdown, provides more flexibility in formatting.

=== Editing Documentation

See <<UsingGradle#rendering-asciidoc-files, UsingGradle.adoc>> to learn how to render `.adoc` files locally to preview the end result of your edits.
Alternatively, you can download the AsciiDoc plugin for IntelliJ, which allows you to preview the changes you have made to your `.adoc` files in real-time.

=== Publishing Documentation

See <<UsingTravis#deploying-github-pages, UsingTravis.adoc>> to learn how to deploy GitHub Pages using Travis.

=== Converting Documentation to PDF format

We use https://www.google.com/chrome/browser/desktop/[Google Chrome] for converting documentation to PDF format, as Chrome's PDF engine preserves hyperlinks used in webpages.

Here are the steps to convert the project documentation files to PDF format.

.  Follow the instructions in <<UsingGradle#rendering-asciidoc-files, UsingGradle.adoc>> to convert the AsciiDoc files in the `docs/` directory to HTML format.
.  Go to your generated HTML files in the `build/docs` folder, right click on them and select `Open with` -> `Google Chrome`.
.  Within Chrome, click on the `Print` option in Chrome's menu.
.  Set the destination to `Save as PDF`, then click `Save` to save a copy of the file in PDF format. For best results, use the settings indicated in the screenshot below.

.Saving documentation as PDF files in Chrome
image::chrome_save_as_pdf.png[width="300"]

[[Docs-SiteWideDocSettings]]
=== Site-wide Documentation Settings

The link:{repoURL}/build.gradle[`build.gradle`] file specifies some project-specific https://asciidoctor.org/docs/user-manual/#attributes[asciidoc attributes] which affects how all documentation files within this project are rendered.

[TIP]
Attributes left unset in the `build.gradle` file will use their *default value*, if any.

[cols="1,2a,1", options="header"]
.List of site-wide attributes
|===
|Attribute name |Description |Default value

|`site-name`
|The name of the website.
If set, the name will be displayed near the top of the page.
|_not set_

|`site-githuburl`
|URL to the site's repository on https://github.com[GitHub].
Setting this will add a "View on GitHub" link in the navigation bar.
|_not set_

|`site-seedu`
|Define this attribute if the project is an official SE-EDU project.
This will render the SE-EDU navigation bar at the top of the page, and add some SE-EDU-specific navigation items.
|_not set_

|===

[[Docs-PerFileDocSettings]]
=== Per-file Documentation Settings

Each `.adoc` file may also specify some file-specific https://asciidoctor.org/docs/user-manual/#attributes[asciidoc attributes] which affects how the file is rendered.

Asciidoctor's https://asciidoctor.org/docs/user-manual/#builtin-attributes[built-in attributes] may be specified and used as well.

[TIP]
Attributes left unset in `.adoc` files will use their *default value*, if any.

[cols="1,2a,1", options="header"]
.List of per-file attributes, excluding Asciidoctor's built-in attributes
|===
|Attribute name |Description |Default value

|`site-section`
|Site section that the document belongs to.
This will cause the associated item in the navigation bar to be highlighted.
One of: `UserGuide`, `DeveloperGuide`, ``LearningOutcomes``{asterisk}, `AboutUs`, `ContactUs`

_{asterisk} Official SE-EDU projects only_
|_not set_

|`no-site-header`
|Set this attribute to remove the site navigation bar.
|_not set_

|===

=== Site Template

The files in link:{repoURL}/docs/stylesheets[`docs/stylesheets`] are the https://developer.mozilla.org/en-US/docs/Web/CSS[CSS stylesheets] of the site.
You can modify them to change some properties of the site's design.

The files in link:{repoURL}/docs/templates[`docs/templates`] controls the rendering of `.adoc` files into HTML5.
These template files are written in a mixture of https://www.ruby-lang.org[Ruby] and http://slim-lang.com[Slim].

[WARNING]
====
Modifying the template files in link:{repoURL}/docs/templates[`docs/templates`] requires some knowledge and experience with Ruby and Asciidoctor's API.
You should only modify them if you need greater control over the site's layout than what stylesheets can provide.
The SE-EDU team does not provide support for modified template files.
====

[[Testing]]
== Testing

=== Running Tests

There are three ways to run tests.

[TIP]
The most reliable way to run tests is the 3rd one. The first two methods might fail some GUI tests due to platform/resolution-specific idiosyncrasies.

*Method 1: Using IntelliJ JUnit test runner*

* To run all tests, right-click on the `src/test/java` folder and choose `Run 'All Tests'`
* To run a subset of tests, you can right-click on a test package, test class, or a test and choose `Run 'ABC'`

*Method 2: Using Gradle*

* Open a console and run the command `gradlew clean allTests` (Mac/Linux: `./gradlew clean allTests`)

[NOTE]
See <<UsingGradle#, UsingGradle.adoc>> for more info on how to run tests using Gradle.

*Method 3: Using Gradle (headless)*

Thanks to the https://github.com/TestFX/TestFX[TestFX] library we use, our GUI tests can be run in the _headless_ mode. In the headless mode, GUI tests do not show up on the screen. That means the developer can do other things on the Computer while the tests are running.

To run tests in headless mode, open a console and run the command `gradlew clean headless allTests` (Mac/Linux: `./gradlew clean headless allTests`)

=== Types of tests

We have two types of tests:

.  *GUI Tests* - These are tests involving the GUI. They include,
.. _System Tests_ that test the entire App by simulating user actions on the GUI. These are in the `systemtests` package.
.. _Unit tests_ that test the individual components. These are in `seedu.address.ui` package.
.  *Non-GUI Tests* - These are tests not involving the GUI. They include,
..  _Unit tests_ targeting the lowest level methods/classes. +
e.g. `seedu.address.commons.StringUtilTest`
..  _Integration tests_ that are checking the integration of multiple code units (those code units are assumed to be working). +
e.g. `seedu.address.storage.StorageManagerTest`
..  Hybrids of unit and integration tests. These test are checking multiple code units as well as how the are connected together. +
e.g. `seedu.address.logic.LogicManagerTest`


=== Troubleshooting Testing
**Problem: `HelpWindowTest` fails with a `NullPointerException`.**

* Reason: One of its dependencies, `HelpWindow.html` in `src/main/resources/docs` is missing.
* Solution: Execute Gradle task `processResources`.

== Dev Ops

=== Build Automation

See <<UsingGradle#, UsingGradle.adoc>> to learn how to use Gradle for build automation.

=== Continuous Integration

We use https://travis-ci.org/[Travis CI] and https://www.appveyor.com/[AppVeyor] to perform _Continuous Integration_ on our projects. See <<UsingTravis#, UsingTravis.adoc>> and <<UsingAppVeyor#, UsingAppVeyor.adoc>> for more details.

=== Coverage Reporting

We use https://coveralls.io/[Coveralls] to track the code coverage of our projects. See <<UsingCoveralls#, UsingCoveralls.adoc>> for more details.

=== Documentation Previews
When a pull request has changes to asciidoc files, you can use https://www.netlify.com/[Netlify] to see a preview of how the HTML version of those asciidoc files will look like when the pull request is merged. See <<UsingNetlify#, UsingNetlify.adoc>> for more details.

=== Making a Release

Here are the steps to create a new release.

.  Update the version number in link:{repoURL}/src/main/java/seedu/address/MainApp.java[`MainApp.java`].
.  Generate a JAR file <<UsingGradle#creating-the-jar-file, using Gradle>>.
.  Tag the repo with the version number. e.g. `v0.1`
.  https://help.github.com/articles/creating-releases/[Create a new release using GitHub] and upload the JAR file you created.

=== Managing Dependencies

A project often depends on third-party libraries. For example, Address Book depends on the http://wiki.fasterxml.com/JacksonHome[Jackson library] for XML parsing. Managing these _dependencies_ can be automated using Gradle. For example, Gradle can download the dependencies automatically, which is better than these alternatives. +
a. Include those libraries in the repo (this bloats the repo size) +
b. Require developers to download those libraries manually (this creates extra work for developers)

[appendix]
== Product Scope

*Target user profile*:

* needs a quick and easy way to edit images
* has a lot of images to edit
* appreciates the power that traditional editing software provides
* familiar with the command line
* prefers typing over mouse input
* is reasonably comfortable using CLI app

*Value proposition*: view, preview and edit images quickly in a streamlined, modular and repeatable process

[appendix]
== User Stories

Priorities: High (must have) - `* * \*`, Medium (nice to have) - `* \*`, Low (unlikely to have) - `*`

[width="59%",cols="22%,<23%,<25%,<30%",options="header",]
|=======================================================================
|Priority |As a ... |I want to ... |So that I can...
|`* * *` |photographer |edit an image |enhance an image

|`* * *` |photographer |mass edit images |avoid repeating similar tasks

|`* * *` |photographer |see detailed information about a photo |immidiately know what post-processing tools to apply

|`* * *` |photographer |define my own set of transformations |avoid repetitive typing of commands

|`* * *` |photographer |see the preview of the transformations before committing to disk |explore the effects of transformations

|`* *` |photographer |be able to upload my photos to the cloud (Google Photos) |safely store and share my photos across devices

|`* *` |web developer |generate static image assets |convert, compress and resize images to be ready for web deployment from raw images

|`*` |web developer or photographer |add captions or watermarks to images |to protect my intellectual property

|=======================================================================

_{More to be added}_

[appendix]
== Use Cases

(For all use cases below, the *System* is `Piconso` and the *Actor* is the `user`, unless specified otherwise)

[discrete]
=== Use case: Editing an image

*MSS*

1.  User opens an image
2.  User uses the CLI to describe a set of transformations to the image
3.  Piconso shows a preview of the outcome
4.  User can save the outcome/transformation to disk
+
Use case ends.

*Extensions*

[none]
* 1a. The given image cannot be opened.
+
[none]
** 1a1. Piconso shows an error message.
+
Use case resumes at step 1.

* 2a. User is unsatisfied with the last transformation.
+
[none]
** 2a1. User can undo the last transformation.
+
Use case resumes at step 2.

[discrete]
=== Use case: Define a set of transformations

*MSS*

1.  User edits an image (from use case Editing an image)
2.  Piconso displays transformations done on the right side pane
3.  User enters command to save the set of transformations
4.  Piconso requests for a name for the set
5.  User enters a name
6.  Piconso saves the set
+
Use case ends.

*Extensions*

[none]
* 5a. The input name is already used.
+
[none]
** 5a1. Piconso asks if user wants to overwrite to previously stored set.
+
Use case resumes at step 4.

[discrete]
=== Use case: Mass edit images

*MSS*

1.  User selects a range of images
2.  User defines an optional alternate directory to save output
3.  User applies a known set of transformations to the set of images
4.  Output from step 3 is saved in directory defined in step 2 and user is notified
+
Use case ends.

*Extensions*

[none]
* 1a. Selected range is an empty set.
+
[none]
** 1a1. Piconso shows an error message.
+
Use case resumes at step 1.

[discrete]
=== Use case: Add caption or watermark to image

*MSS*

1.  User opens an image
2.  Piconso displays the image in the preview pane
3.  User inputs caption or watermark text into input
4.  Piconso displays the caption/watermark in the preview pane
+
Use case ends.


_{More to be added}_

[appendix]
== Non Functional Requirements

.  Export images in different formats and sizes.
.  Have quick access to various filter options.
.  View detailed information about images.
.  Navigate directories efficiently.

[appendix]
== Glossary

[[batch]] Batch::
Images that are currently being viewed. For example, if there are 16 images in the current directory, the default "batch" viewed would be the first 10 photos. Upon a `next` command, the "batch" switches to the next 10.

[[transformation]] Transformation::
Action that is performed on an image

[appendix]
== Instructions for Manual Testing

_{To be updated}_
